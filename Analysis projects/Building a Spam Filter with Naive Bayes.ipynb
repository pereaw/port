{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770b1a5e",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our goal is to write a program that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll use a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more details on this page, where you can also find some of the papers authored by Tiago A. Almeida and José María Gómez Hidalgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823c5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2b4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Library/datasci/datasets/SMSSpamCollection.csv\", sep = '\\t', header = None,\n",
    "                names = ['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61cf05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d6dcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9a272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()/5572"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f84e7a",
   "metadata": {},
   "source": [
    "4825 of our 5572 entries are labeled as not spam. We can do a little bit of calculation to get that we have approximately 86.6% non-spam, and 13.4% spam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4be877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import a splitter from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21c47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.iloc[:,1:], df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4c0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 1,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2282c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865829\n",
       "spam    0.134171\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee003ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866368\n",
       "spam    0.133632\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a5e42",
   "metadata": {},
   "source": [
    "We see that the training and test sets have roughly equal proportions of spam and non-spam\n",
    "\n",
    "# Cleaning Data\n",
    "\n",
    "We'll remove all of the punctuation and make all of the messages lower case in an attempt to normalize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970b23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The regex \\W will grab all non words. \n",
    "X_train.SMS = X_train.SMS.str.replace(r'\\W', ' ', regex = True).str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c330483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357                          no  he joined today itself \n",
       "5568                 will ü b going to esplanade fr home \n",
       "2987    reply to win  100 weekly  what professional sp...\n",
       "951            awesome  lemme know whenever you re around\n",
       "648     private  your 2003 account statement for shows...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.SMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f2d557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above\n",
    "X_test.SMS = X_test.SMS.str.replace(r'\\W', ' ', regex = True).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3c0f1",
   "metadata": {},
   "source": [
    "# Create a Vocabulary list.\n",
    "We will combine the training and test set to create a more robust vocabulary. Since we have a way to treat words that we have never seen before in the Naive Bayes algorithm, I see no reason not to use all of the data available to simply capture the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4d6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine to make a dictionary. To be honest though this may be cheating.\n",
    "#it may make more sense to make the dictionary purely off of the test set.\n",
    "xwhole = pd.concat([X_test,X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888d0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "xwhole.SMS = xwhole.SMS.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "731c05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for string in xwhole.SMS:\n",
    "    for word in string:\n",
    "        vocabulary.append(word)\n",
    "            \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "271d50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8753"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for repeates to make sure it worked.\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f54f76",
   "metadata": {},
   "source": [
    "# Create the dictionary and transform into a dataset\n",
    "We are now going to create a dictionary using our vocabulary set. We will essentially make it a series of zeroes equal to the length of our entire dataset. What we will then do is iterate through the messages and increase the count at a given index in our dictionary by the number of times the word appears in the sms message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "935ce988",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(xwhole['SMS']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c9aedfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sms in zip(xwhole.index,xwhole.SMS):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6f104327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first5pairs = {k: word_counts_per_sms[k] for k in sorted(word_counts_per_sms.keys())[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "56b899bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>shes</th>\n",
       "      <th>agalla</th>\n",
       "      <th>knock</th>\n",
       "      <th>mobile</th>\n",
       "      <th>at</th>\n",
       "      <th>laready</th>\n",
       "      <th>mymoby</th>\n",
       "      <th>0a</th>\n",
       "      <th>zealand</th>\n",
       "      <th>...</th>\n",
       "      <th>extreme</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>pack</th>\n",
       "      <th>elliot</th>\n",
       "      <th>9061100010</th>\n",
       "      <th>dream</th>\n",
       "      <th>valuable</th>\n",
       "      <th>smsco</th>\n",
       "      <th>pobox334</th>\n",
       "      <th>ec2a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   8  shes  agalla  knock  mobile  at  laready  mymoby  0a  zealand  ...  \\\n",
       "0  0     0       0      0       0   0        0       0   0        0  ...   \n",
       "1  0     0       0      0       0   0        0       0   0        0  ...   \n",
       "2  0     0       0      0       0   0        0       0   0        0  ...   \n",
       "3  0     0       0      0       0   0        0       0   0        0  ...   \n",
       "4  0     0       0      0       0   0        0       0   0        0  ...   \n",
       "\n",
       "   extreme  neighbor  pack  elliot  9061100010  dream  valuable  smsco  \\\n",
       "0        0         0     0       0           0      0         0      0   \n",
       "1        0         0     0       0           0      0         0      0   \n",
       "2        0         0     0       0           0      0         0      0   \n",
       "3        0         0     0       0           0      0         0      0   \n",
       "4        0         0     0       0           0      0         0      0   \n",
       "\n",
       "   pobox334  ec2a  \n",
       "0         0     0  \n",
       "1         0     0  \n",
       "2         0     0  \n",
       "3         0     0  \n",
       "4         0     0  \n",
       "\n",
       "[5 rows x 8753 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms,)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "70b12180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he        1\n",
       "itself    1\n",
       "no        1\n",
       "today     1\n",
       "joined    1\n",
       "Name: 2357, dtype: object"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.loc[2357][X_train_clean.loc[2357] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2bc98ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>8</th>\n",
       "      <th>shes</th>\n",
       "      <th>agalla</th>\n",
       "      <th>knock</th>\n",
       "      <th>mobile</th>\n",
       "      <th>at</th>\n",
       "      <th>laready</th>\n",
       "      <th>mymoby</th>\n",
       "      <th>0a</th>\n",
       "      <th>...</th>\n",
       "      <th>extreme</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>pack</th>\n",
       "      <th>elliot</th>\n",
       "      <th>9061100010</th>\n",
       "      <th>dream</th>\n",
       "      <th>valuable</th>\n",
       "      <th>smsco</th>\n",
       "      <th>pobox334</th>\n",
       "      <th>ec2a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>[ok, i, shall, talk, to, him]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>[eatin, my, lunch]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>[sir, waiting, for, your, mail]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>[wif, my, family, booking, tour, package]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>[no, it, s, not, pride, i, m, almost, lt, gt, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS  8  shes  agalla  \\\n",
       "977                       [ok, i, shall, talk, to, him]  0     0       0   \n",
       "4688                                 [eatin, my, lunch]  0     0       0   \n",
       "142                     [sir, waiting, for, your, mail]  0     0       0   \n",
       "4708          [wif, my, family, booking, tour, package]  0     0       0   \n",
       "5335  [no, it, s, not, pride, i, m, almost, lt, gt, ...  0     0       0   \n",
       "\n",
       "      knock  mobile  at  laready  mymoby  0a  ...  extreme  neighbor  pack  \\\n",
       "977       0       0   0        0       0   0  ...        0         0     0   \n",
       "4688      0       0   0        0       0   0  ...        0         0     0   \n",
       "142       0       0   0        0       0   0  ...        0         0     0   \n",
       "4708      0       0   0        0       0   0  ...        0         0     0   \n",
       "5335      0       0   0        0       0   0  ...        0         0     0   \n",
       "\n",
       "      elliot  9061100010  dream  valuable  smsco  pobox334  ec2a  \n",
       "977        0           0      0         0      0         0     0  \n",
       "4688       0           0      0         0      0         0     0  \n",
       "142        0           0      0         0      0         0     0  \n",
       "4708       0           0      0         0      0         0     0  \n",
       "5335       0           0      0         0      0         0     0  \n",
       "\n",
       "[5 rows x 8754 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean = pd.concat([xwhole, word_counts], axis = 1)\n",
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd78dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['id'] = X_train.index\n",
    "# X_test['id'] = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a4e32971",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_train, X_train_clean], join = \"inner\", axis = 1)\n",
    "X_train_final = X_train_final.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "878574d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he        1\n",
       "itself    1\n",
       "no        1\n",
       "today     1\n",
       "joined    1\n",
       "Name: 2357, dtype: object"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.loc[2357][X_train_final.loc[2357] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "34c33c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>8</th>\n",
       "      <th>shes</th>\n",
       "      <th>agalla</th>\n",
       "      <th>knock</th>\n",
       "      <th>mobile</th>\n",
       "      <th>at</th>\n",
       "      <th>laready</th>\n",
       "      <th>mymoby</th>\n",
       "      <th>0a</th>\n",
       "      <th>...</th>\n",
       "      <th>extreme</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>pack</th>\n",
       "      <th>elliot</th>\n",
       "      <th>9061100010</th>\n",
       "      <th>dream</th>\n",
       "      <th>valuable</th>\n",
       "      <th>smsco</th>\n",
       "      <th>pobox334</th>\n",
       "      <th>ec2a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>[no, he, joined, today, itself]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>[reply, to, win, 100, weekly, what, profession...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>[awesome, lemme, know, whenever, you, re, around]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>[private, your, 2003, account, statement, for,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS  8  shes  agalla  \\\n",
       "2357                    [no, he, joined, today, itself]  0     0       0   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]  0     0       0   \n",
       "2987  [reply, to, win, 100, weekly, what, profession...  0     0       0   \n",
       "951   [awesome, lemme, know, whenever, you, re, around]  0     0       0   \n",
       "648   [private, your, 2003, account, statement, for,...  0     0       0   \n",
       "\n",
       "      knock  mobile  at  laready  mymoby  0a  ...  extreme  neighbor  pack  \\\n",
       "2357      0       0   0        0       0   0  ...        0         0     0   \n",
       "5568      0       0   0        0       0   0  ...        0         0     0   \n",
       "2987      0       0   0        0       0   0  ...        0         0     0   \n",
       "951       0       0   0        0       0   0  ...        0         0     0   \n",
       "648       0       0   0        0       0   0  ...        0         0     0   \n",
       "\n",
       "      elliot  9061100010  dream  valuable  smsco  pobox334  ec2a  \n",
       "2357       0           0      0         0      0         0     0  \n",
       "5568       0           0      0         0      0         0     0  \n",
       "2987       0           0      0         0      0         0     0  \n",
       "951        0           0      0         0      0         0     0  \n",
       "648        0           0      0         0      0         0     0  \n",
       "\n",
       "[5 rows x 8754 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27729d97",
   "metadata": {},
   "source": [
    "# Create the algorithm\n",
    "We now have a good training and test set, it is time to actually make the algorithm for classification. To get started we will be working towards calculating the probability that a message is spam given the contents of the message. We also want to calculate the probability that a message is not spam given the contents of the message.\n",
    "\n",
    "As we are looking to calculate:\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "To do so we will need to calculate:\n",
    "* $P(Spam)$ The probability of spam. We have this from above, 0.134\n",
    "* $P(Ham)$ The probability of ham. We also have this from above. 0.866\n",
    "* $N_{spam}$ The count of total words in all spam messages\n",
    "* $N_{ham}$ The count of total words in all non-spam messages\n",
    "* $N_{vocabulary}$ The count of total words in the vocabulary. We already have this it is 8753.\n",
    "\n",
    "So we now will do some counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "42128c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spam and ham training sets.\n",
    "#Spam and ham training sets.\n",
    "spam_id = y_train[y_train == \"spam\"].index\n",
    "ham_id = y_train[y_train == \"ham\"].index\n",
    "\n",
    "X_train_spam = X_train_final.loc[spam_id]\n",
    "X_train_ham = X_train_final.loc[ham_id]\n",
    "\n",
    "#Nspam\n",
    "N_spam = X_train_spam.SMS.apply(len).sum()\n",
    "N_ham = X_train_ham.SMS.apply(len).sum()\n",
    "\n",
    "#Nvocabulary\n",
    "N_vocabulary = 8753\n",
    "\n",
    "#Alpha\n",
    "a = 1\n",
    "\n",
    "#probs\n",
    "pspam = len(spam_id)/len(X_train_final)\n",
    "pham = len(ham_id)/len(X_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ad15e",
   "metadata": {},
   "source": [
    "# Calculating Parameters\n",
    "\n",
    "We need to calculate $P(w_i|Spam)$ and $P(w_i|Ham)$. These two conditional probabilities form the basis of our comparison for the Naive Bayes algorithm. Again each of these probabilities is just the probability that a certain word exists in a message given that it is spam or non-spam. These can be calculated with the following:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "To do so we will create a spam dictionary and a non-spam dictionary, then fill in the probabilities using our constants calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f48ade97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize words and set probabilities to 0\n",
    "spam_dict = {}\n",
    "ham_dict = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    spam_dict[word] = 0\n",
    "    ham_dict[word] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "00c38c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probabilities for SPAM and for HAM\n",
    "\n",
    "for word in vocabulary:\n",
    "    prob_spam = (X_train_spam[word].sum() + a) / (N_spam + a * N_vocabulary)\n",
    "    prob_ham = (X_train_ham[word].sum() + a) / (N_ham + a * N_vocabulary)\n",
    "    spam_dict[word] = prob_spam\n",
    "    ham_dict[word] = prob_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34506c63",
   "metadata": {},
   "source": [
    "# Classifying A New Message\n",
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "* Takes in as input a new message $(w_1, w_2, ..., w_n)$.\n",
    "* Calculates $P(Spam|w_1, w_2, ..., w_n)$ and $P(Ham|w_1, w_2, ..., w_n)$.\n",
    "* Compares the values of $P(Spam|w_1, w_2, ..., w_n)$ and $P(Ham|w_1, w_2, ..., w_n)$, and:\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as ham.\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) < P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as spam.\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) = P(Spam|w_1, w_2, ..., w_n)$, then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b0fd250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classifier function.\n",
    "\n",
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = pspam\n",
    "    p_ham_given_message = pham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "            \n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "    \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb63ab4",
   "metadata": {},
   "source": [
    "Some quick testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "c5e8e517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 6.825887390849328e-26\n",
      "P(Ham|message): 1.909125784210236e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "df47fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.983681276035583e-25\n",
      "P(Ham|message): 2.604255852554336e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238c306",
   "metadata": {},
   "source": [
    "# Measuring the Spam Filter's Accuracy\n",
    "\n",
    "The two results above look promising, but let's see how well the filter does on our test set, which has 1,115 messages.\n",
    "\n",
    "We'll start by writing a function that returns classification labels instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ad90f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly modify function to return the label for test validation\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = pspam\n",
    "    p_ham_given_message = pham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "890129dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted'] = X_test['SMS'].apply(classify_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2c3ade60",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([X_test,y_test], join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "941164ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1091\n",
      "total: 1115\n",
      "Accuracy: 0.97847533632287\n"
     ]
    }
   ],
   "source": [
    "correct = (final.predicted == final.Label).sum()\n",
    "total = len(final)\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"Correct:\", correct)\n",
    "print(\"total:\", total)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e4bdd",
   "metadata": {},
   "source": [
    "Our accuracy on the filter is roughly 98% which is quite good and shows a large increase over the baseline of 86% accuracy of simply labeling everything non-spam.\n",
    "\n",
    "# Some Potential Next Steps\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.74% on the test set we used, which is a pretty good result. Our initial goal was an accuracy of over 86%, and we managed to do way better than that.\n",
    "\n",
    "Next steps could include:\n",
    "\n",
    "* Analyze the  messages that were classified incorrectly and try to figure out why the algorithm classified them incorrectly\n",
    "* Make the filtering process more complex by making the algorithm sensitive to letter case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
